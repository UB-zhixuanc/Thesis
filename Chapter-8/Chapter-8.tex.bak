%SourceDoc ../YourName-Dissertation.tex
\chapter{Future Work} \label{chapter:Future-Work}
\section{Improvement of the software}
This research presented in this thesis developed the first version of the 3D plume simulation software.
My plans for future work includes four aspects of the software: physics model, numerical techniques, software performance and software usability.

\subsection{More comprehensive physics model}
The highest priority of the future research will be given to improvment of the physics model. Simplification based on assumptions facilitated the development of the software from all sides. On the other hand, these assumptions also impair the predition capability of the software. The first assumption that should be removed is the stationary atmosphere assumption, which gets rid of wind field from the model. Without accounting for the effect of the wind fields, the software can only be used to simulating strong plume, for which the effects of windfields is ignorable. It is straight forward to include wind field in physical model. No changes in governing equations are needed. Only the pressure outlet boundary condition needs to be changed. More challenges will come from numerical techniques for imposing the new types of boundary conditions in SPH. There are few researches on such topic up to date. Let alone successful implementations in real complicated phenomena simulation. Besides the stationary atmosphere assumption, the immediate dynamics and thermal dyanmics equilibrium assumption can be removed, too. In that case, each phase will be described by a full set of mass conservation equation, momentum equations and energy equation. Another assumption, which assumes that the erupted material is well mixed and behaves like a single phase fluid, will need to be removed if more subtle phenomena are of interest, such as, the aggregation, falling down of solid particles, phase change of $HO_2$ et al. Including of wind field is indispensable while including of other physical effects depend on specific eruption scenario and phenomena of interest. PDAC\citep{neri2003multiparticle} adopts true multiphase governing equations and might serve as a good point to get start. ATHAM  \citep{oberhuber1998volcanic}, which accounts for several microphysics in the model, would also be a good reference for including more microphysics. 1D plume models  \citep{bursik2001effect, pouget2016sensitivity, folch2016fplume} are now pretty comprehensive, conclusions based on 1D plume simulation would also provide merit for more comprehensive 3D plume development.

\subsection{Advanced numerical technique}
SPH, even though is considered as a promising method, is still not considered as a serious candidate to become tomorrow's numerical tool. One of the main reason of this is that SPH still has unknown properties, and many questions remain unanswered on a purely theoretical ground, such as convergence, numerical stability, boundary conditions, kernel properties, time marching, existence and properties of solutions.
Adopting of more advanced numerical techniques will greatly depend on progress in purely theoretical understanding of SPH. 
Besides these more general aspects, accuracy and prediction capability of the software can be improve if the following numerical techniques can be implemented successfully. 
\begin{itemize}
\item {A better way to handle ``mixing issue". As discussed in first chapter, classical SPH has problems in correctly integrating fluid instabilities and mixing at boundaries \citet{read2010resolving}. There are different opinions on the sources of the ``mixing issue" and different strategies to handle this issue among researchers \citep{chen1999improvement, ritchie2001multiphase, agertz2007fundamental, wadsley2008treatment, price2008modelling, read2010resolving, borgani2012hydrodynamic}. A better understanding on ``mixing issue" and new techniques to tackle ``mixing issue" is critical for improving accuracy of the software.}
\item {Adaptive SPH particles size \citep{lopez2013dynamic,draxler2015hysplit,vacondio2016variable} is one of the advanced numerical techniques that might be worthwhile to explore. Benefits of successfully implementing such techniques are multiple folders. Number of particles (the discretized points) can be reduced by assigning fine resolution only when necessary and hence computational cost could be reduced. Accuracy could be increased in refined areas such as interface between volcano plume and surrounding atmosphere. Losing of strict conservation of momentum and energy caused by uneuqal particle mass could also be relieved by adopting the adaptive particle size scheme. The algorithm for particle splitting has to specify the number of split (daughter) particles, their distribution, spacing and kernel size. Vice verse for particle coalescing. The adaptive resolution techniques could make it feasible for simulating of umbrella stage of volcano plume development, which involves larger time scale and spcae sclae.}
\item {A LANS type of turbulence model is adopted and extended in current plume model. I would be interesting (maybe necessary) to compare the effects of using different types of turbulence models.}
\end{itemize}

\subsection{Computational efficiency and parallel scalability}
The computational efficiency and scalability of the software is enough for implementations presented in Chapter 6 and Chapter 7. However future extending of the software by including more physics and phases would impose higher requirement. Adopting of new numerical techniques could also raise new challenges. In addition, even for other applications, current computational efficiency is not enough. For example, the attempt of simulating umbrella stage of volcano plume development was failed as it involves a much larger computational domain and much longger physical time. The following strategies might worthwile to attempt to handle these challenges and demands. 

\begin{itemize}
\item {A better domain decomposition strategy is worthwhile to try. Current SFC based domain decomposition strategy pays enough attention to load balance. No constraint included in the algorithm to minimizing overlaping particles and hence minimizing communications. Either avoiding splitting domain through high-particle-density area or recuding "length" of interface between subdomains could reduce amount of information that needs to be communicated. What's more, the dynamic halo domain algorithm might lead to heavy communication overhead due to irregular shape of computational domain.}
\item {Current way for handling hash conflict is adding a linked list, which can increase memory accessing time dramatically when the list is long. Extra time spending on memory accessing would lead to increase of workload of these particles in the linked list. A dynamic way of determing workload of these particle in a more precise way is necessary. In addition, an alternative way with lower memory access cost, for handle hash conflictions, is desired.}
\item {The current basic data structure adopts indirect memory access pattern. To access physical quantities associated with a particle, the pointer to the HashEntry is first found through hash function and then the pointer to the particle is founded based on HashEntry. Finally the physical quantity will be access based on pointer to the particle object. That is to say, to load physical quantities of a particles, the memory needs to be accessed for several times.
So the time spend on memory access (time on waiting for data loading from memory) might be much more than that spend on computing with such zigzags memory accessing pattern. So eliminating of one or two intermediate pointers is highly desired.}
\item {As the capacity of " memory access buses" is the bottle neck of current code, hybrid parallelization that combines shared memory mode and distributed memory mode would not increase the computational efficiency as expected. However, after adopting a less zigzags memory access partten, the hybrid parallelization can greatly increase computational efficiency and scalability due to significant decrease in communication.}
\item {Any efforts to take advantage of heterogeneous platforms and tackle challenges related to diversity and heterogeneity of hardware are also necessary.}
\end{itemize}

\subsection{Improve usability}
The usability of the software could be improved in several aspects, for example, putting all input parameters in a single file, or at lease, avoiding re-compile if input parameters changed. Several utilities should be developed for determining smoothing lengths, particle masses and domain specifications.
A wrap up around the solvers, which could provide well defined user interface, is highly desirable for users purely interested in application study. Post processing in this thesis were carried out based on some low efficience paraview based python/matlab scripts, which requires proficiency in paraview, python and matlab to use. Actually, it is not written for users usage and requires getting familiar with source code to use them. An efficient and user-friendly post processing module is necessary, too.

\section{Future implementations}
Beside improving the forecast capability, the parallel efficiency and usabilitiy of the software, more implementations are desired. These implementations will also help to identify hidden bugs and defects of the software and will drive future software development.
We propose several potential implementations.
\begin{itemize}
\item {Simulating of other strong eruptions. The current model is suitable for simulating eruptions in which wind field, large size solid particles and micro-physics play ignorable role during plume development. It is also desired that there are enough observational data available for certain eruption to be suitable for case study. One eruption at hand is the second phase of 2010 eruptions of Eyjafjallaj√∂kull. However, the eruption conditions of Eyjafjallaj√∂kull varied in a large range leading to top heights varying in a large range. In addition, the quick cooling down and extra water fraction due to metling of ice might not able to properly accounted for by current model.}
\item {Eruption condition sensitivity study. Sensitivity studies with respect to eruption parameters have been conducted based on other 1D and 3D plume models. However, it is still valuable to confirm their conclusions with a new model and test the capacity of this new model.}
\item {Sensitivity studies on other aspects of the volcano eruption. For example, uniform and parabolic eruption velocity profiles are readily available in the software. There are also four different types of atmosphere conditions available: uniform, purely hydrostatic, approximation model based on observation, realistic atmosphere based on input data. Sensitivity study regarding these aspects can be easily done.}
\item {Combining the plume development model with other VATDs. A combination of Plume-SPH with one of the VATDs, PUFF, is implemented in this thesis. However, more comprehensive 3D VATDs are available. It might be worthwhile to combine the 3D plume model with other more comprehensive 3D VATDs.}
\item {Combining the plume model with underground magma reservior models. Current plume development simulations are based on eruption parameters that are obtained from post-eruption estimations. An altertive way is combining the plume model development model with magma reservior models that can accurately predict eruption conditions.}
\item {Itegrating the current plume model into existing uncertainty and data integration framework for volcanic ash hazards forecasting. Uncertainties in volcaninc plume modeling and ash transportation forecast would not be eliminated by comprehensive 3D plume model. Dynamic eruption condition estimation is always necessary when modeling real eruptions, during which eruption conditions changes along time. However, the computational efficiency has to be improved first. The current computational speed is not fast enough to support either uncertainty quanlification nor data integration.}
\end{itemize}